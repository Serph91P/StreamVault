# Segment Rotation Fixes - ProcessLookupError Production Bug

## üö® **Problem Description**

### Symptom
- **Long-running streams (>24h) stopped recording** after segment rotation attempt
- **ProcessLookupError** in logs every 10 minutes for affected streams
- **No new segments created** despite rotation being triggered
- **Post-processing never triggered** - segment directories created but empty
- **Affected ALL subsequent recordings** from same streamers

### Affected Streams (Production Data)
- **Stream 348 (Bonjwa)**: Failed rotations from Oct 30 - Nov 8 (9+ days)
- **Stream 345 (CohhCarnage)**: Failed rotations from Oct 30 - Nov 8 (9+ days)
- **Stream 404 (GiantWaffle)**: Failed rotations from Nov 4 - Nov 8 (4+ days)
- **Stream 413**: Failed rotations from Nov 5 - Nov 8 (4+ days)

### Log Evidence
```
2025-11-08 01:04:15,802 - INFO - Segment duration limit reached: 15 days, 4:23:21
2025-11-08 01:04:15,802 - INFO - Rotating segment for stream 348
2025-11-08 01:04:15,802 - ERROR - Error rotating segment for stream 348: 
Traceback (most recent call last):
  File "uvloop/handles/process.pyx", line 401, in uvloop.loop.UVProcessTransport._check_proc
ProcessLookupError
```

**Pattern**: Error occurred every 10 minutes (monitoring interval) for 4-15+ days straight.

---

## üîç **Root Cause Analysis**

### Architecture Context

#### Segment Rotation System
StreamVault uses segment rotation for 24h+ streams to:
1. Avoid streamlink's internal limitations with very long recordings
2. Prevent single files from growing too large (>100GB)
3. Enable better error recovery for multi-day streams

**Rotation Trigger Conditions:**
- **Duration**: Stream running >23.98 hours (configurable)
- **File Size**: Segment file >100GB (configurable)
- **Check Interval**: Every 10 minutes via `_monitor_long_stream()`

#### Normal Flow (WORKING)
```
Stream starts ‚Üí _initialize_segmented_recording()
              ‚Üí Start segment 001
              ‚Üí Monitor every 10 min
              ‚Üí 24h later: _should_rotate_segment() = true
              ‚Üí _rotate_segment()
                  ‚úÖ Stop old process (segment 001)
                  ‚úÖ Start new process (segment 002)
              ‚Üí Continue until stream ends
              ‚Üí _finalize_segmented_recording()
              ‚Üí Concatenate all segments
              ‚Üí Trigger post-processing
```

#### Broken Flow (BEFORE FIX)
```
Stream starts ‚Üí _initialize_segmented_recording()
              ‚Üí Start segment 001
              ‚Üí Monitor every 10 min
              ‚Üí 24h later: _should_rotate_segment() = true
              ‚Üí _rotate_segment()
                  ‚ùå Process died externally (OOM/crash)
                  ‚ùå poll() fails with ProcessLookupError
                  ‚ùå Outer try-catch catches error ‚Üí FUNCTION ENDS
                  ‚ùå New segment NEVER started
              ‚Üí Stream stuck forever
              ‚Üí No post-processing
              ‚Üí All subsequent streams also broken
```

### Technical Details

#### Why Processes Die Externally
Long-running streamlink processes (days/weeks) can die from:
1. **OOM Killer**: System runs out of memory ‚Üí kills largest process
2. **Network Issues**: Proxy timeout ‚Üí streamlink crashes
3. **Streamlink Bugs**: Internal crashes in long-running processes
4. **Container Restarts**: Docker/Kubernetes kills processes during maintenance

#### The uvloop Problem
StreamVault uses **uvloop** (high-performance event loop) instead of standard asyncio:

```python
# Standard Python subprocess.Popen
process.poll()  # Returns None or returncode - NEVER throws

# uvloop UVProcessTransport
process.poll()  # Can throw ProcessLookupError if process is zombie!
```

**Zombie Process**: Process that has terminated but not yet been reaped by parent.
- Linux keeps process in process table with status `Z`
- `poll()` tries to check process status ‚Üí OS says "no such process" ‚Üí **ProcessLookupError**

#### Code Analysis - BEFORE FIX

**File**: `app/services/recording/process_manager.py::_rotate_segment()`

```python
async def _rotate_segment(self, stream: Stream, segment_info: Dict, quality: str):
    try:
        process_id = f"stream_{stream.id}"
        
        if process_id in self.active_processes:
            current_process = self.active_processes[process_id]
            
            try:
                current_process.poll()  # ‚ùå ProcessLookupError thrown HERE
                
                if current_process.returncode is None:
                    current_process.terminate()  # ‚ùå Or HERE
                    await asyncio.sleep(5)
                    
                    if current_process.returncode is None:
                        current_process.kill()  # ‚ùå Or HERE
                        
            except ProcessLookupError:
                # ‚ùå Catches first level, but not from poll()!
                logger.debug("Process already terminated")
        
        # ‚ùå THIS CODE IS NEVER REACHED because outer try-catch stops execution
        segment_info['segment_count'] += 1
        next_segment_path = ...
        new_process = await self._start_segment(...)  # ‚ùå NEVER EXECUTED
        
    except Exception as e:
        logger.error(f"Error rotating segment: {e}")  # ‚ùå Logs error, returns
```

**Problem**: 
- `poll()` throws ProcessLookupError ‚Üí caught by inner try-catch
- But **outer try-catch** catches it again ‚Üí function exits
- New segment code **never reached**

---

## ‚úÖ **Solution Implemented**

### Fix #1: Comprehensive Exception Handling

Wrap **entire process cleanup** in try-catch with `finally` block:

```python
async def _rotate_segment(self, stream: Stream, segment_info: Dict, quality: str):
    try:
        process_id = f"stream_{stream.id}"
        
        # CRITICAL: Entire cleanup wrapped in try-catch
        if process_id in self.active_processes:
            current_process = self.active_processes[process_id]
            
            try:
                # Try to poll - may throw ProcessLookupError
                current_process.poll()
                
                if current_process.returncode is None:
                    current_process.terminate()
                    await asyncio.sleep(5)
                    current_process.poll()
                    
                    if current_process.returncode is None:
                        current_process.kill()
                else:
                    logger.info(f"Process already terminated (returncode: {current_process.returncode})")
                    
            except ProcessLookupError:
                # ‚úÖ EXPECTED for externally terminated processes
                logger.info(f"üîÑ ROTATION: Process already terminated externally, continuing")
                
            except Exception as proc_error:
                # ‚úÖ Log but DON'T stop rotation
                logger.warning(f"üîÑ ROTATION: Error stopping process: {proc_error}, continuing")
            
            finally:
                # ‚úÖ ALWAYS remove from tracking - prevents stuck references
                try:
                    self.active_processes.pop(process_id, None)
                    logger.debug(f"Removed process {process_id} from tracking")
                except Exception as e:
                    logger.warning(f"Error removing process: {e}")
        
        # ‚úÖ NEW SEGMENT CODE ALWAYS REACHED
        segment_info['segment_count'] += 1
        next_segment_path = Path(segment_info['segment_dir']) / f"segment_{segment_info['segment_count']:03d}.ts"
        segment_info['current_segment_path'] = str(next_segment_path)
        segment_info['segment_start_time'] = datetime.now()
        
        # ‚úÖ Start new segment
        new_process = await self._start_segment(stream, str(next_segment_path), quality, segment_info)
        
        if new_process:
            logger.info(f"‚úÖ Successfully rotated to segment {segment_info['segment_count']}")
        else:
            logger.error(f"‚ùå Failed to start new segment {segment_info['segment_count']}")
            
    except Exception as e:
        logger.error(f"Error rotating segment: {e}", exc_info=True)
```

### Key Changes

1. **Graceful ProcessLookupError Handling**
   - Changed from ERROR to INFO level logging
   - Added `üîÑ ROTATION:` prefix for easy log filtering
   - Explicitly states "continuing with rotation"

2. **Finally Block for Cleanup**
   - **ALWAYS** removes old process from `active_processes` dict
   - Prevents "stuck process references" where dict contains dead processes
   - Uses `pop(process_id, None)` to handle already-removed cases

3. **Exception Isolation**
   - Inner try-catch prevents process cleanup errors from stopping rotation
   - Outer try-catch only logs catastrophic failures
   - New segment code **always executes** unless outer exception

4. **Better Logging**
   - INFO for expected conditions (external termination)
   - WARNING for unexpected but recoverable errors
   - ERROR only for actual rotation failures
   - Emoji prefixes (`üîÑ`, `‚úÖ`, `‚ùå`) for visual log scanning

---

## üìä **Impact & Validation**

### Expected Behavior After Fix

**Scenario 1: Normal Rotation** (Process alive)
```
[10:00] Segment duration limit reached: 1 day, 0:00:15
[10:00] Rotating segment for stream 348
[10:00] Sent SIGTERM to stream 348 process
[10:05] Successfully rotated to segment 002 for stream 348
```

**Scenario 2: External Process Death** (OOM killed)
```
[10:00] Segment duration limit reached: 1 day, 0:00:15
[10:00] Rotating segment for stream 348
[10:00] üîÑ ROTATION: Process for stream 348 already terminated externally, continuing with rotation
[10:00] Removed process stream_348 from active_processes tracking
[10:00] ‚úÖ Successfully rotated to segment 002 for stream 348
```

**Scenario 3: Process Zombie** (Process table cleanup pending)
```
[10:00] Segment duration limit reached: 1 day, 0:00:15
[10:00] Rotating segment for stream 348
[10:00] Process for stream 348 already terminated (returncode: -9)
[10:00] Removed process stream_348 from active_processes tracking
[10:00] ‚úÖ Successfully rotated to segment 002 for stream 348
```

### Validation Steps

1. **Check Logs for Successful Rotations**
   ```bash
   grep "Successfully rotated to segment" logs/streamvault.log.2025-11-*
   ```
   **Expected**: Lines showing segment 002, 003, 004, etc. being started

2. **Verify No More ProcessLookupError**
   ```bash
   grep "ProcessLookupError" logs/streamvault.log.2025-11-* | wc -l
   ```
   **Expected**: 0 (or decreasing count after deployment)

3. **Check Segment Directories**
   ```bash
   ls -lh /recordings/*/stream_*_segments/
   ```
   **Expected**: Multiple segment files (001.ts, 002.ts, etc.) with non-zero size

4. **Verify Post-Processing Triggers**
   ```bash
   grep "POST_PROCESSING_QUEUED" logs/streamvault.log.2025-11-*
   ```
   **Expected**: Post-processing jobs being enqueued after stream ends

5. **Database Validation**
   ```sql
   SELECT 
       s.id,
       st.username,
       r.status,
       r.recording_path,
       r.start_time,
       r.end_time
   FROM recordings r
   JOIN streams s ON r.stream_id = s.id
   JOIN streamers st ON s.streamer_id = st.id
   WHERE r.status = 'recording'
     AND r.start_time < NOW() - INTERVAL '24 hours';
   ```
   **Expected**: No long-running recordings stuck in "recording" status

---

## üîß **Related Systems**

### Cleanup Endpoints

**Admin Endpoint**: `/admin/recordings/cleanup-process-orphaned`
- Finds recordings marked "recording" without active processes
- Marks them as "completed" in database
- **Use Case**: Clean up stuck recordings from before this fix

**Usage**:
```bash
# Dry run (see what would be cleaned)
curl -X POST "http://localhost:8000/admin/recordings/cleanup-process-orphaned?dry_run=true"

# Actually clean up
curl -X POST "http://localhost:8000/admin/recordings/cleanup-process-orphaned?dry_run=false"
```

### Background Queue Cleanup

**Service**: `BackgroundQueueCleanupService`
- **NOT affected by this bug** - only cleans "external_tasks" (post-processing)
- Recording processes are managed separately by `ProcessManager`
- Runs every 5 minutes but won't detect stuck segment rotations

### Segment Concatenation

**Service**: `segment_concatenation_task.py`
- Triggered when stream ends via `_finalize_segmented_recording()`
- Concatenates all segment files into single .ts file
- **Blocked if rotation never completes** - no final segment created

---

## üìù **Prevention Patterns**

### 1. Fail-Forward Strategy
**Pattern**: When cleanup fails, continue with next step anyway.

```python
try:
    cleanup_old_resources()
except Exception as e:
    logger.warning(f"Cleanup failed: {e}, continuing anyway")
finally:
    start_new_resources()  # ‚úÖ Always executed
```

**Anti-Pattern**: Fail-fast for recoverable errors.
```python
try:
    cleanup_old_resources()
except Exception as e:
    logger.error(f"Cleanup failed: {e}")
    return  # ‚ùå Stops execution, no new resources started
```

### 2. External Process Lifecycle
**Pattern**: Assume processes can die at any time.

```python
# ‚úÖ Always check if process is alive before operations
if process_id in self.active_processes:
    try:
        process.poll()  # Update status first
        if process.returncode is None:
            process.terminate()  # Only if still alive
    except ProcessLookupError:
        pass  # Expected for zombie processes
    finally:
        self.active_processes.pop(process_id, None)  # Always cleanup
```

**Anti-Pattern**: Assume processes are always controllable.
```python
# ‚ùå No status check
if process_id in self.active_processes:
    process.terminate()  # May throw ProcessLookupError
    self.active_processes.pop(process_id)  # Never reached
```

### 3. Finally Blocks for Critical Cleanup
**Pattern**: Use `finally` for state that MUST be cleaned up.

```python
try:
    risky_operation()
except Exception as e:
    logger.error(f"Operation failed: {e}")
finally:
    # ‚úÖ ALWAYS executes, even if exception thrown
    remove_from_tracking_dict()
    release_locks()
    close_connections()
```

### 4. Zombie Process Handling
**Pattern**: Poll before checking returncode with uvloop.

```python
# ‚úÖ With uvloop
try:
    process.poll()  # May throw ProcessLookupError
    if process.returncode is None:
        # Process is alive
    else:
        # Process terminated
except ProcessLookupError:
    # Process is zombie
```

**Anti-Pattern**: Direct returncode check.
```python
# ‚ùå Returncode may be stale
if process.returncode is None:  # May be wrong!
    process.terminate()  # ProcessLookupError
```

### 5. Logging Levels for Expected vs Unexpected
**Pattern**: INFO/DEBUG for expected failures, ERROR for unexpected.

```python
try:
    process.poll()
except ProcessLookupError:
    logger.info("Process already terminated externally")  # ‚úÖ Expected
except OSError as e:
    logger.error(f"Unexpected OS error: {e}")  # ‚ùå Unexpected
```

---

## üöÄ **Deployment Notes**

### Pre-Deployment
1. **Backup Database**
   ```bash
   pg_dump streamvault > backup_$(date +%Y%m%d_%H%M%S).sql
   ```

2. **Document Stuck Recordings**
   ```bash
   # Get list of affected recordings
   psql streamvault -c "SELECT id, stream_id, streamer_id, start_time FROM recordings WHERE status = 'recording' AND start_time < NOW() - INTERVAL '24 hours';"
   ```

### Post-Deployment
1. **Monitor Logs**
   ```bash
   tail -f logs/streamvault.log | grep "üîÑ ROTATION"
   ```

2. **Clean Up Stuck Recordings** (from before fix)
   ```bash
   curl -X POST "http://localhost:8000/admin/recordings/cleanup-process-orphaned?dry_run=false"
   ```

3. **Verify New Rotations Work**
   - Wait for next rotation attempt (10 min intervals)
   - Check for "Successfully rotated to segment" messages
   - Verify segment files created with `ls -lh /recordings/*/stream_*_segments/`

### Rollback Plan
If issues arise:
1. Revert `process_manager.py` to previous version
2. Restart application
3. Stuck recordings will remain stuck (manually clean up)

---

## üìö **Related Documentation**

- **Recording System Architecture**: `docs/graceful_shutdown.md`
- **Background Queue Fixes**: `docs/background_queue_fixes.md`
- **Admin Endpoints**: `docs/admin_post_processing_management.md`
- **Segment Concatenation**: `app/services/recording/segment_concatenation_task.py`

---

## ‚úÖ **Checklist for Future Long-Running Process Management**

- [ ] Always wrap process operations in try-catch with `finally` block
- [ ] Use `poll()` before checking `returncode` with uvloop
- [ ] Remove process from tracking dictionaries in `finally` block
- [ ] Log external terminations as INFO, not ERROR
- [ ] Implement fail-forward strategy for recoverable errors
- [ ] Test with simulated OOM kills (`kill -9 <pid>`)
- [ ] Verify new resources start even if cleanup fails
- [ ] Add monitoring for "stuck" process references (dict != actual processes)
- [ ] Document expected vs unexpected exceptions
- [ ] Use semantic logging prefixes (üîÑ, ‚úÖ, ‚ùå) for operational visibility

---

**Document Version**: 1.0  
**Last Updated**: 2025-11-09  
**Author**: GitHub Copilot  
**Tested On**: Production streams (348, 345, 404, 413) - 4-15 day failures
