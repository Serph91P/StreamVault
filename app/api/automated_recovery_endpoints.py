"""
Automated Recovery API Endpoints

Automatisierung der existierenden Recovery-Services:
- Unified Recovery (umfassend)
- Orphaned Recovery (orphaned segments)
- Failed Recovery (fehlgeschlagene Post-Processing)
"""

from fastapi import APIRouter, HTTPException, BackgroundTasks
from typing import Dict, Any, Optional
import logging
import asyncio
from datetime import datetime, timedelta, timezone

logger = logging.getLogger("streamvault")

router = APIRouter(prefix="/api/recovery/automated", tags=["automated-recovery"])

# Constants
DEFAULT_RECOVERY_INTERVAL = 300  # 5 Minuten Standard
ERROR_DELAY_ON_FAILURE = 60  # Pause bei Fehlern in Sekunden
MIN_INTERVAL_MINUTES = 1
MAX_INTERVAL_MINUTES = 1440

# Thread-safe state management
class AutomatedRecoveryState:
    """Thread-safe state management for automated recovery"""
    
    def __init__(self):
        self._lock = asyncio.Lock()
        self._running = False
        self._interval = DEFAULT_RECOVERY_INTERVAL
        self._last_run = None
        self._stats = {
            "total_runs": 0,
            "successful_runs": 0,
            "failed_runs": 0,
            "last_error": None
        }
        self._task: Optional[asyncio.Task] = None
    
    async def is_running(self) -> bool:
        async with self._lock:
            return self._running
    
    async def set_running(self, running: bool):
        async with self._lock:
            self._running = running
    
    async def get_interval(self) -> int:
        async with self._lock:
            return self._interval
    
    async def set_interval(self, interval: int):
        async with self._lock:
            self._interval = interval
    
    async def get_last_run(self) -> Optional[datetime]:
        async with self._lock:
            return self._last_run
    
    async def set_last_run(self, timestamp: datetime):
        async with self._lock:
            self._last_run = timestamp
    
    async def get_stats(self) -> Dict[str, Any]:
        async with self._lock:
            return self._stats.copy()
    
    async def increment_total_runs(self):
        async with self._lock:
            self._stats["total_runs"] += 1
    
    async def increment_successful_runs(self):
        async with self._lock:
            self._stats["successful_runs"] += 1
            self._stats["last_error"] = None
    
    async def increment_failed_runs(self, error: str):
        async with self._lock:
            self._stats["failed_runs"] += 1
            self._stats["last_error"] = error
    
    async def set_task(self, task: Optional[asyncio.Task]):
        async with self._lock:
            self._task = task
    
    async def get_task(self) -> Optional[asyncio.Task]:
        async with self._lock:
            return self._task
    
    async def cancel_task(self):
        async with self._lock:
            if self._task and not self._task.done():
                self._task.cancel()
                self._task = None

# Global state instance
recovery_state = AutomatedRecoveryState()


async def run_comprehensive_recovery() -> Dict[str, Any]:
    """
    F√ºhrt umfassende Recovery mit allen existierenden Services aus
    
    Nutzt:
    1. Unified Recovery - f√ºr komplette Analyse
    2. Orphaned Recovery - f√ºr orphaned segments
    3. Failed Recovery - f√ºr fehlgeschlagene Post-Processing
    """
    await recovery_state.increment_total_runs()
    now = datetime.now(timezone.utc)
    await recovery_state.set_last_run(now)
    
    results = {
        "start_time": now.isoformat(),
        "unified_recovery": None,
        "orphaned_recovery": None, 
        "failed_recovery": None,
        "total_recoveries": 0,
        "success": False
    }
    
    try:
        # 1. Unified Recovery (umfassendste Analyse)
        logger.info("üîß Starting unified recovery...")
        try:
            from ..services.recording.unified_recovery_service import get_unified_recovery_service
            unified_service = await get_unified_recovery_service()
            unified_stats = await unified_service.comprehensive_recovery_scan(
                max_age_hours=72, 
                dry_run=False
            )
            results["unified_recovery"] = {
                "success": True,
                "orphaned_segments": unified_stats.orphaned_segments,
                "failed_post_processing": unified_stats.failed_post_processing,
                "recovered_recordings": unified_stats.recovered_recordings,
                "triggered_post_processing": unified_stats.triggered_post_processing,
                "total_size_gb": unified_stats.total_size_gb
            }
            results["total_recoveries"] += unified_stats.recovered_recordings + unified_stats.triggered_post_processing
            logger.info(f"‚úÖ Unified recovery: {unified_stats.recovered_recordings} recovered, {unified_stats.triggered_post_processing} triggered")
        except Exception as e:
            logger.error(f"‚ùå Unified recovery failed: {e}")
            results["unified_recovery"] = {"success": False, "error": str(e)}
        
        # 2. Orphaned Recovery (zus√§tzlich f√ºr orphaned segments)
        logger.info("üîß Starting orphaned recovery...")
        try:
            from ..services.recording.orphaned_recovery_service import get_orphaned_recovery_service
            orphaned_service = await get_orphaned_recovery_service()
            orphaned_result = await orphaned_service.scan_and_recover_orphaned_recordings(
                max_age_hours=48, 
                dry_run=False
            )
            results["orphaned_recovery"] = {
                "success": True,
                "recovery_triggered": orphaned_result.get("recovery_triggered", 0),
                "orphaned_found": orphaned_result.get("orphaned_found", 0)
            }
            results["total_recoveries"] += orphaned_result.get("recovery_triggered", 0)
            logger.info(f"‚úÖ Orphaned recovery: {orphaned_result.get('recovery_triggered', 0)} triggered")
        except Exception as e:
            logger.error(f"‚ùå Orphaned recovery failed: {e}")
            results["orphaned_recovery"] = {"success": False, "error": str(e)}
        
        # 3. Failed Recovery (spezifisch f√ºr fehlgeschlagene Post-Processing)  
        logger.info("üîß Starting failed recovery...")
        try:
            from ..services.recording.failed_recording_recovery_service import get_failed_recovery_service
            failed_service = await get_failed_recovery_service()
            failed_result = await failed_service.scan_and_recover_failed_recordings(dry_run=False)
            results["failed_recovery"] = {
                "success": True,
                "recovery_triggered": failed_result.get("recovery_triggered", 0),
                "failed_found": failed_result.get("failed_found", 0),
                "recoverable_found": failed_result.get("recoverable_found", 0)
            }
            results["total_recoveries"] += failed_result.get("recovery_triggered", 0)
            logger.info(f"‚úÖ Failed recovery: {failed_result.get('recovery_triggered', 0)} triggered")
        except Exception as e:
            logger.error(f"‚ùå Failed recovery failed: {e}")
            results["failed_recovery"] = {"success": False, "error": str(e)}
        
        results["end_time"] = datetime.now(timezone.utc).isoformat()
        results["success"] = True
        await recovery_state.increment_successful_runs()
        
        logger.info(f"üéâ Comprehensive recovery completed: {results['total_recoveries']} total recoveries")
        return results
        
    except Exception as e:
        results["end_time"] = datetime.now(timezone.utc).isoformat()
        results["success"] = False
        results["error"] = str(e)
        await recovery_state.increment_failed_runs(str(e))
        logger.error(f"‚ùå Comprehensive recovery failed: {e}")
        return results


async def automated_recovery_loop():
    """
    Hauptschleife f√ºr automatisierte Recovery
    
    L√§uft kontinuierlich und f√ºhrt alle recovery_interval Sekunden
    umfassende Recovery durch.
    """
    interval = await recovery_state.get_interval()
    logger.info(f"üöÄ Starting automated recovery loop (interval: {interval}s)")
    
    while await recovery_state.is_running():
        try:
            logger.info("üîÑ Running automated recovery cycle...")
            result = await run_comprehensive_recovery()
            
            if result["success"]:
                logger.info(f"‚úÖ Recovery cycle completed: {result['total_recoveries']} total recoveries")
            else:
                logger.error(f"‚ùå Recovery cycle failed: {result.get('error', 'Unknown error')}")
            
            # Aktuelle Interval-Zeit abrufen (k√∂nnte ge√§ndert worden sein)
            current_interval = await recovery_state.get_interval()
            await asyncio.sleep(current_interval)
            
        except asyncio.CancelledError:
            logger.info("üõë Automated recovery loop cancelled")
            break
        except Exception as e:
            logger.error(f"‚ùå Error in automated recovery loop: {e}")
            await asyncio.sleep(ERROR_DELAY_ON_FAILURE)
    
    await recovery_state.set_running(False)
    logger.info("üõë Automated recovery loop stopped")


@router.post("/start")
async def start_automated_recovery(
    interval_minutes: int = 5
):
    """
    Startet automatisierte Recovery mit allen existierenden Services
    
    Args:
        interval_minutes: Intervall zwischen Recovery-L√§ufen (Standard: 5 Minuten)
    """
    try:
        if await recovery_state.is_running():
            return {
                "success": False,
                "message": "Automated recovery is already running"
            }
        
        if interval_minutes < MIN_INTERVAL_MINUTES or interval_minutes > MAX_INTERVAL_MINUTES:
            raise HTTPException(
                status_code=400, 
                detail=f"Interval must be between {MIN_INTERVAL_MINUTES} and {MAX_INTERVAL_MINUTES} minutes"
            )
        
        await recovery_state.set_interval(interval_minutes * 60)
        await recovery_state.set_running(True)
        
        # Erstelle persistente Task statt Background Task
        task = asyncio.create_task(automated_recovery_loop())
        await recovery_state.set_task(task)
        
        return {
            "success": True,
            "message": "Automated comprehensive recovery started",
            "interval_minutes": interval_minutes,
            "services": ["unified_recovery", "orphaned_recovery", "failed_recovery"]
        }
        
    except Exception as e:
        logger.error(f"Failed to start automated recovery: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to start recovery: {str(e)}")


@router.post("/stop")
async def stop_automated_recovery():
    """Stoppt die automatisierte Recovery"""
    try:
        if not await recovery_state.is_running():
            return {
                "success": False,
                "message": "Automated recovery is not running"
            }
        
        await recovery_state.set_running(False)
        await recovery_state.cancel_task()
        
        return {
            "success": True,
            "message": "Automated recovery stopped"
        }
        
    except Exception as e:
        logger.error(f"Failed to stop automated recovery: {e}")
        raise HTTPException(status_code=500, detail=f"Failed to stop recovery: {str(e)}")


@router.post("/run-once")
async def run_manual_recovery():
    """
    F√ºhrt einmalig umfassende Recovery aus (alle Services)
    """
    try:
        result = await run_comprehensive_recovery()
        return result
        
    except Exception as e:
        logger.error(f"Manual comprehensive recovery failed: {e}")
        raise HTTPException(status_code=500, detail=f"Recovery failed: {str(e)}")


@router.get("/status")
async def get_recovery_status():
    """Gibt Status der automatisierten Recovery zur√ºck"""
    last_run = await recovery_state.get_last_run()
    stats = await recovery_state.get_stats()
    interval = await recovery_state.get_interval()
    
    return {
        "success": True,
        "data": {
            "is_running": await recovery_state.is_running(),
            "interval_minutes": interval // 60,
            "last_run": last_run.isoformat() if last_run else None,
            "statistics": stats,
            "services": ["unified_recovery", "orphaned_recovery", "failed_recovery"]
        }
    }


@router.post("/configure")
async def configure_recovery(
    interval_minutes: int = None
):
    """
    Konfiguriert automatisierte Recovery
    
    Args:
        interval_minutes: Neues Intervall zwischen Recovery-L√§ufen
        
    Note: √Ñnderungen werden beim n√§chsten Zyklus wirksam, nicht sofort
    """
    try:
        if interval_minutes is not None:
            if interval_minutes < MIN_INTERVAL_MINUTES or interval_minutes > MAX_INTERVAL_MINUTES:
                raise HTTPException(
                    status_code=400, 
                    detail=f"Interval must be between {MIN_INTERVAL_MINUTES} and {MAX_INTERVAL_MINUTES} minutes"
                )
            await recovery_state.set_interval(interval_minutes * 60)
        
        current_interval = await recovery_state.get_interval()
        
        return {
            "success": True,
            "message": "Configuration updated (changes take effect on next cycle)",
            "current_config": {
                "interval_minutes": current_interval // 60,
                "is_running": await recovery_state.is_running()
            }
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Failed to configure recovery: {e}")
        raise HTTPException(status_code=500, detail=f"Configuration failed: {str(e)}")


@router.get("/test-services")
async def test_recovery_services():
    """
    Testet alle Recovery-Services (dry run)
    
    N√ºtzlich um zu pr√ºfen ob alle Services verf√ºgbar sind
    """
    results = {
        "unified_recovery": None,
        "orphaned_recovery": None,
        "failed_recovery": None
    }
    
    # Test Unified Recovery
    try:
        from ..services.recording.unified_recovery_service import get_unified_recovery_service
        unified_service = await get_unified_recovery_service()
        unified_stats = await unified_service.comprehensive_recovery_scan(max_age_hours=72, dry_run=True)
        results["unified_recovery"] = {
            "available": True,
            "orphaned_segments": unified_stats.orphaned_segments,
            "failed_post_processing": unified_stats.failed_post_processing,
            "total_size_gb": unified_stats.total_size_gb
        }
    except Exception as e:
        results["unified_recovery"] = {"available": False, "error": str(e)}
    
    # Test Orphaned Recovery  
    try:
        from ..services.recording.orphaned_recovery_service import get_orphaned_recovery_service
        orphaned_service = await get_orphaned_recovery_service()
        orphaned_result = await orphaned_service.scan_and_recover_orphaned_recordings(max_age_hours=48, dry_run=True)
        results["orphaned_recovery"] = {
            "available": True,
            "orphaned_found": orphaned_result.get("orphaned_found", 0)
        }
    except Exception as e:
        results["orphaned_recovery"] = {"available": False, "error": str(e)}
    
    # Test Failed Recovery
    try:
        from ..services.recording.failed_recording_recovery_service import get_failed_recovery_service
        failed_service = await get_failed_recovery_service()
        failed_result = await failed_service.scan_and_recover_failed_recordings(dry_run=True)
        results["failed_recovery"] = {
            "available": True,
            "failed_found": failed_result.get("failed_found", 0),
            "recoverable_found": failed_result.get("recoverable_found", 0)
        }
    except Exception as e:
        results["failed_recovery"] = {"available": False, "error": str(e)}
    
    return {
        "success": True,
        "services": results,
        "all_available": all(service.get("available", False) for service in results.values())
    }
